{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Load libraries\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "SBP0PnmCqPsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "plt.style.use('dark_background')\n",
        "%matplotlib inline\n",
        "\n",
        "# Pipeline module\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Scaling, encoding, and imputation modules\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
        "\n",
        "# Column transformation modules\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Module for categorical variables\n",
        "from pandas.api.types import CategoricalDtype\n",
        "\n",
        "# Modules for building custom encoders and transformers\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Regression and classification modules\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier"
      ],
      "metadata": {
        "id": "nR3jyY7J92uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Mount Google Drive if running in Colab\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "xWkw-yhSq-mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Mount Google drive folder if running in Colab\n",
        "if('google.colab' in sys.modules):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount = True)\n",
        "    # Change path below starting from /content/drive/MyDrive/Colab Notebooks/\n",
        "    # depending on how data is organized inside your Colab Notebooks folder in\n",
        "    # Google Drive\n",
        "    DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/MSIS Coursework/EvenSem2024MAHE'\n",
        "    DATA_DIR = DIR+'/Data/'\n",
        "else:\n",
        "    DATA_DIR = 'Data/'"
      ],
      "metadata": {
        "id": "Ob5N3i5CrDS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Create lists of ordinal, categorical, and continuous features\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Vb0FKFNtBRoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create lists of ordinal, categorical, and continuous features\n",
        "ordinal_features = ['Rating']\n",
        "categorical_features = ['Gender']\n",
        "continuous_features = ['Age']"
      ],
      "metadata": {
        "id": "_NkbbnuMBScF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "User-defined function to load the movie ratings dataset and assign 'category' datatype to ordinal and categorical columns\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "2f7Zz1f5Aqvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "  ## Load movie ratings data\n",
        "  file = DATA_DIR+'ratings.csv'\n",
        "  df = pd.read_csv(file, sep = ',', header = 0, index_col = 0)\n",
        "  df[ordinal_features + categorical_features] = df[ordinal_features + categorical_features].astype('category')\n",
        "  return(df)"
      ],
      "metadata": {
        "id": "mNGowHl1A1pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load movie ratings data\n",
        "df = load_data()\n",
        "print('Movie ratings dataset')\n",
        "print('-----------')\n",
        "print('Initial number of samples = %d'%(df.shape[0]))\n",
        "print('Initial number of features = %d\\n'%(df.shape[1]))\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "F-oPAIqkqM8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Plot percentage of missing values (NaNs) for each feature\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "rinV2aIDr-Fv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Plot percentage of missing values (NaNs) for each feature\n",
        "cutoff = 10 # we will remove features missing in more than 20% of the samples\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "percent_missing = (df.isna().sum() / df.shape[0]) * 100\n",
        "percent_missing.plot(kind = 'bar', color = cm.rainbow(np.linspace(0, 1, 2))[(percent_missing <= cutoff).values.astype(int)])\n",
        "fig.suptitle('Percentage Missing Values Across All Features', fontsize = 12)\n",
        "plt.xlabel('Feature', fontsize = 12)\n",
        "plt.ylabel('% Missing Values', fontsize = 12);"
      ],
      "metadata": {
        "id": "YjjbtEs79SlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Print unique values in each ordinal and categorical features\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ztg9EQt0_FGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Print unique values in each ordinal and categorical features\n",
        "print(df[ordinal_features + categorical_features].nunique())\n",
        "print('\\nUnique values in ordinal and categorical features')\n",
        "print('---------------------------------------------------')\n",
        "unique_values = {col:list(df[col].unique()) for col in ordinal_features + categorical_features}\n",
        "for key, value in unique_values.items():\n",
        "  print(key, value)"
      ],
      "metadata": {
        "id": "WI05A0eo_Ffb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Impute ordinal and categorical columns using SimpleImputer()\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ajNZb7vStDif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Impute ordinal and categorical columns using SimpleImputer()\n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
        "imputer.fit_transform(df.loc[:, ordinal_features + categorical_features])"
      ],
      "metadata": {
        "id": "FwItxza3tPiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impute ordinal and categorical columns using KNNImputer().\n",
        "\n",
        "Is there any issue in this approach?"
      ],
      "metadata": {
        "id": "ZFXWT-0Wtu_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Impute ordinal and categorical columns using KNNImputer()\n",
        "imputer = KNNImputer(n_neighbors = 2)\n",
        "imputer.fit_transform(df.loc[:, ordinal_features + categorical_features])"
      ],
      "metadata": {
        "id": "bv7u10_y0zyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Impute ordinal and categorical columns using IterativeImputer().\n",
        "\n",
        "Is there any issue in this approach?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ZYue4rO46qLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = IterativeImputer(estimator=RandomForestClassifier(random_state=0), max_iter=20)\n",
        "imputer.fit_transform(df.loc[:, ordinal_features + categorical_features])"
      ],
      "metadata": {
        "id": "89XLu_mF60Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Impute continuous column using KNNImputer()\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "VOQ0j_C5uWON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Impute continuous column using KNNImputer()\n",
        "imputer = KNNImputer(n_neighbors = 2)\n",
        "imputer.fit_transform(df.loc[:, continuous_features])"
      ],
      "metadata": {
        "id": "-NIBpx8nucZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Impute continuous column using IterativeImputer()\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "QKcGTkzK7R40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = IterativeImputer(estimator=RandomForestRegressor(random_state=0), max_iter=20)\n",
        "imputer.fit_transform(df.loc[:, continuous_features])"
      ],
      "metadata": {
        "id": "VgdOz1_t7Uzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "One-hot encode the categorical column using OneHotEncoder().\n",
        "\n",
        "Is there any issue in this approach?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jueZ7wcMyqh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## One-hot encode the categorical column using OneHotEncoder()\n",
        "OneHotEncoder().fit_transform(df.loc[:, categorical_features]).todense()"
      ],
      "metadata": {
        "id": "xKWA01vUtHVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Ordinal encode the ordinal column using OrdinalEncoder().\n",
        "\n",
        "Is there any issue in this approach?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "c1mDPjsi1N1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Ordinal encode the ordinal column using OrdinalEncoder()\n",
        "ratings_order = ['Bad', 'Neutral', 'Good']\n",
        "OrdinalEncoder(categories = [ratings_order]).fit_transform(df.loc[:, ordinal_features])"
      ],
      "metadata": {
        "id": "kseIaVojzDIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "ChatGPT prompt and resulting code: I have a movie ratings dataset in a file called ratings.csv. There are 3 features: 1) Rating, an ordinal column with 3 levels Good, Bad, Average (2) Age, a continuous column, and (3) Gender, a categorical column with 3 levels M, F, U. All columns have missing values. Can you write a Python code that will implement a pipeline that will (a) impute and encode the categorical and ordinal features and (b) impute and scale the continuous feature. Note that you have to use either KNNImputer() or IterativeImputer() for imputation purpose and not the SimpleImputer()\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Cc7oMPn2r9NG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-HKgzo8TsBni"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "854f9ff9f945bab8ba5d04e939504df285fc62eb45b7a687b185fca2375459b7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}